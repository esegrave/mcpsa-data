{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize modules and globals\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetype = 'highered'\n",
    "local_html = './data/' + filetype + '/html/html.htm'\n",
    "yearID = 'ddYear'\n",
    "gradeID = 'ddStudentGroup'\n",
    "groupID = 'ddInOutState'\n",
    "exportName = 'spExport'\n",
    "rawfileName = 'Gradsattendingcollege.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--Select--', '2018-19', '2017-18', '2016-17', '2015-16', '2014-15', '2013-14', '2012-13', '2011-12', '2010-11', '2009-10', '2008-09', '2007-08', '2006-07', '2005-06', '2004-05', '2003-04']\n",
      "['All Colleges and Universities', 'MA Colleges and Universities', 'Out-of-State Colleges and Universities']\n",
      "['All Students', 'Female', 'Male', 'High Needs', 'English Learner', 'Low Income', 'Economically Disadvantaged', 'Students w/disabilities', 'Afr. Amer./Black', 'Amer. Ind. or Alaska Nat.', 'Asian', 'Hispanic/Latino', 'Multi-race, Non-Hisp./Lat.', 'Nat. Haw. or Pacif. Isl.', 'White']\n"
     ]
    }
   ],
   "source": [
    "# load html to data\n",
    "with open(local_html) as html:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# scrape available years, grades, and student groups\n",
    "years = []\n",
    "\n",
    "for item in soup.find(id=yearID).children:\n",
    "    if item.string != '\\n':\n",
    "        years.append(item.string)\n",
    "\n",
    "print(years)      \n",
    "\n",
    "groups = []\n",
    "\n",
    "for item in soup.find(id=groupID).children:\n",
    "    if item.string != '\\n':\n",
    "        groups.append(item.string)\n",
    "\n",
    "print(groups)\n",
    "\n",
    "grades = []\n",
    "\n",
    "for item in soup.find(id=gradeID).children:\n",
    "    if item.string != '\\n':\n",
    "        grades.append(item.string)\n",
    "        \n",
    "print(grades)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all combinations of year/grade/group, downloading each file and renaming it\n",
    "# recreate html page, with each option selected\n",
    "for year in years:\n",
    "    for grade in grades:\n",
    "        for group in groups:\n",
    "            for item in soup.find(id=yearID).children:\n",
    "                try:\n",
    "                    if item.string == year:\n",
    "                        item['selected'] = 'selected'\n",
    "                    if item.string != year:\n",
    "                        del item['selected']\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            for item in soup.find(id=gradeID).children:\n",
    "                try:\n",
    "                    if item.string == grade:\n",
    "                        item['selected'] = 'selected'\n",
    "                    if item.string != grade:\n",
    "                        del item['selected']\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            for item in soup.find(id=groupID).children:\n",
    "                try:\n",
    "                    if item.string == group:\n",
    "                        item['selected'] = 'selected'\n",
    "                    if item.string != group:\n",
    "                        del item['selected']\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            html_file = open('./data/' + filetype + '/html/temp.html','w')\n",
    "            html_file.write(soup.prettify())\n",
    "            html_file.close()\n",
    "            driver.get('file:///'+os.getcwd()+'/' + '/data/' + filetype + '/html/temp.html')\n",
    "\n",
    "            # simulate export click with selenium\n",
    "            download_button = driver.find_element_by_id(exportName)\n",
    "            download_button.click()\n",
    "\n",
    "            # wait for file to download\n",
    "            time.sleep(5)\n",
    "\n",
    "            # rename file\n",
    "        #     filename = 'mcas_' + grade.replace('.', '').replace('/', '') + '_' + group.replace('.', '').replace('/', '') + '_' + year.replace('.', '').replace('/', '') + '.xlsx'\n",
    "            filename = 'ma_'+ filetype + '_' + grade.replace('.', '').replace('/', '') + '_' + group.replace('.', '').replace('/', '') + '_' + year.replace('.', '').replace('/', '') + '.xlsx'\n",
    "            os.rename('/Users/esegr1/Downloads/' + rawfileName,'/Users/esegr1/Downloads/' + filename)\n",
    "            shutil.move(os.path.join('/Users/esegr1/Downloads/',filename), os.path.join('/Users/esegr1/Documents/repos/mcpsa/data/' + filetype + '/raw', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
