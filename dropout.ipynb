{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize modules and globals\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetype = 'dropout'\n",
    "local_html = './data/' + filetype + '/html/html.htm'\n",
    "yearID = 'ctl00_ContentPlaceHolder1_ddYear'\n",
    "gradeID = 'ctl00_ContentPlaceHolder1_ddGrade'\n",
    "groupID = 'ctl00_ContentPlaceHolder1_ddSubgroup'\n",
    "exportName = 'ctl00_ContentPlaceHolder1_spExport'\n",
    "rawfileName = 'dropout.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-19', '2017-18', '2016-17', '2015-16', '2014-15', '2013-14', '2012-13', '2011-12', '2010-11', '2009-10', '2008-09', '2007-08']\n",
      "['All Students', 'Female', 'Male', 'Economically Disadvantaged', 'High Needs', 'English Learner', 'Low Income', 'Students with disabilities', 'African American/Black', 'American Indian or Alaskan Native', 'Asian', 'Hispanic or Latino', 'Multi-race, non-Hispanic or Latino', 'Native Hawaiian or Pacific Islander', 'White']\n"
     ]
    }
   ],
   "source": [
    "# load html to data\n",
    "with open(local_html) as html:\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# scrape available years, grades, and student groups\n",
    "years = []\n",
    "\n",
    "for item in soup.find(id=yearID).children:\n",
    "    if item.string != '\\n':\n",
    "        years.append(item.string)\n",
    "\n",
    "print(years)\n",
    "\n",
    "# grades = []\n",
    "\n",
    "# for item in soup.find(id=gradeID).children:\n",
    "#     if item.string != '\\n':\n",
    "#         grades.append(item.string)\n",
    "        \n",
    "# print(grades)        \n",
    "\n",
    "groups = []\n",
    "\n",
    "for item in soup.find(id=groupID).children:\n",
    "    if item.string != '\\n':\n",
    "        groups.append(item.string)\n",
    "\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all combinations of year/grade/group, downloading each file and renaming it\n",
    "# recreate html page, with each option selected\n",
    "for year in years:\n",
    "#     for grade in grades:\n",
    "    for group in groups:\n",
    "        for item in soup.find(id=yearID).children:\n",
    "            try:\n",
    "                if item.string == year:\n",
    "                    item['selected'] = 'selected'\n",
    "                if item.string != year:\n",
    "                    del item['selected']\n",
    "            except TypeError:\n",
    "                pass\n",
    "#     for item in soup.find(id=gradeID).children:\n",
    "#         try:\n",
    "#             if item.string == grade:\n",
    "#                 item['selected'] = 'selected'\n",
    "#             if item.string != grade:\n",
    "#                 del item['selected']\n",
    "#         except TypeError:\n",
    "#             pass\n",
    "        for item in soup.find(id=groupID).children:\n",
    "            try:\n",
    "                if item.string == group:\n",
    "                    item['selected'] = 'selected'\n",
    "                if item.string != group:\n",
    "                    del item['selected']\n",
    "            except TypeError:\n",
    "                pass\n",
    "        html_file = open('./data/' + filetype + '/html/temp.html','w')\n",
    "        html_file.write(soup.prettify())\n",
    "        html_file.close()\n",
    "        driver.get('file:///'+os.getcwd()+'/' + '/data/' + filetype + '/html/temp.html')\n",
    "\n",
    "        # simulate export click with selenium\n",
    "        download_button = driver.find_element_by_id(exportName)\n",
    "        download_button.click()\n",
    "\n",
    "        # wait for file to download\n",
    "        time.sleep(5)\n",
    "\n",
    "        # rename file\n",
    "    #     filename = 'mcas_' + grade.replace('.', '').replace('/', '') + '_' + group.replace('.', '').replace('/', '') + '_' + year.replace('.', '').replace('/', '') + '.xlsx'\n",
    "        filename = 'ma_'+ filetype + '_' + group.replace('.', '').replace('/', '') + '_' + year.replace('.', '').replace('/', '') + '.xlsx'\n",
    "        os.rename('/Users/esegr1/Downloads/' + rawfileName,'/Users/esegr1/Downloads/' + filename)\n",
    "        shutil.move(os.path.join('/Users/esegr1/Downloads/',filename), os.path.join('/Users/esegr1/Documents/repos/mcpsa/data/' + filetype + '/raw', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
